{
 "metadata": {
  "name": "",
  "signature": "sha256:971db0d428f563e45d334274e854306cd997d344cbdfa233e582fef481abb4e7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "sys.path.append('/software/python/anaconda/lib/python2.7/site-packages/') #for h5py\n",
      "import glob\n",
      "import numpy as np\n",
      "import scipy.io\n",
      "import h5py\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rootdir='/mindhive/saxelab2/FGE/'\n",
      "savefile=os.path.join(rootdir,'stimdata','behavioralintensity.csv')\n",
      "behavedir=os.path.join(rootdir, 'behavioural')\n",
      "stimfile=os.path.join(rootdir, 'stimdata','FGE_stims.csv')\n",
      "behavioralfiles=glob.glob(os.path.join(behavedir, 'SAX_FGE_*.FGE_main.*.mat'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractbehave(bf):\n",
      "    '''loads a behavioral file, returns behavioral dict. so many hacks because interfacing with .mat files is hell!'''\n",
      "    #some .mats require the h5py, whereas others require scipy. lord knows why.\n",
      "    try:\n",
      "        b = scipy.io.loadmat(bf)\n",
      "    except:\n",
      "        try:\n",
      "            b = hdfbehaveextract(bf)\n",
      "        except:\n",
      "            b = hdfbehaveextract2(bf)\n",
      "    for key in b.keys():\n",
      "        try:\n",
      "            b[key] = list(b[key].squeeze())\n",
      "        except:\n",
      "            pass\n",
      "    return b\n",
      "\n",
      "\n",
      "def hdfbehaveextract(bf):\n",
      "    '''function to extract .mats using h5py. output should be a dict with items corresponding to .mat structure fields, just as would be returned by scipy.io.loadmat'''\n",
      "    bhdf = h5py.File(bf, 'r')\n",
      "    bips = int(bhdf['ips'][0][0])\n",
      "    brt = [float(el) for el in bhdf['RT'][0]]\n",
      "    brun = [int(el) for el in bhdf['run'][0]]\n",
      "    bkey = [int(el) for el in bhdf['key'][0]]\n",
      "    stims_unicode = [bhdf[el] for el in bhdf['item_orders'][0]]\n",
      "    bitem_orders = []\n",
      "    bspm_i = bhdf['spm_inputs']\n",
      "    numconditions = len(bspm_i['name'])\n",
      "    bspm_inputs = []\n",
      "    for c in range(numconditions):\n",
      "        onsets = bhdf[bspm_i['ons'][c][0]]\n",
      "        onsets = np.array([[float(el)] for el in onsets[0]])\n",
      "        durations = bhdf[bspm_i['dur'][c][0]]\n",
      "        durations = np.array([[el] for el in durations[0]])\n",
      "        condition = ''.join(unichr(i[0]) for i in bhdf[bspm_i['name'][c][0]])\n",
      "        row = ([condition], onsets, durations)\n",
      "        bspm_inputs.append(row)\n",
      "    bspm_inputs = bspm_inputs\n",
      "    for stim in stims_unicode:\n",
      "        bitem_orders.append([u''.join(unichr(i[0]) for i in stim)])\n",
      "    b = {'ips': bips, 'spm_inputs': bspm_inputs, 'RT': brt, 'item_orders': bitem_orders, 'run': brun, 'key': bkey}\n",
      "    return b\n",
      "\n",
      "\n",
      "def hdfbehaveextract2(bf):\n",
      "    '''function to extract .mats using h5py. output should be a dict with items corresponding to .mat structure fields, just as would be returned by scipy.io.loadmat'''\n",
      "    bhdf = h5py.File(bf, 'r')\n",
      "    bips = int(bhdf['ips'][0][0])\n",
      "    brt = [float(el) for el in bhdf['RT'][0]]\n",
      "    brun = [int(el) for el in bhdf['run'][0]]\n",
      "    bkey = [int(el) for el in bhdf['key'][0]]\n",
      "    stims_unicode = bhdf['item_orders']\n",
      "    numtrials = stims_unicode.shape[1]\n",
      "    bitem_orders = []\n",
      "    for trial in range(numtrials):\n",
      "        bitem_orders.append([u''.join(unichr(i[trial]) for i in stims_unicode.value)])\n",
      "    bspm_i = bhdf['spm_inputs']\n",
      "    numconditions = len(bspm_i['name'])\n",
      "    bspm_inputs = []\n",
      "    for c in range(numconditions):\n",
      "        onsets = bhdf[bspm_i['ons'][c][0]]\n",
      "        onsets = np.array([[float(el)] for el in onsets[0]])\n",
      "        durations = bhdf[bspm_i['dur'][c][0]]\n",
      "        durations = np.array([[el] for el in durations[0]])\n",
      "        condition = ''.join(unichr(i[0]) for i in bhdf[bspm_i['name'][c][0]])\n",
      "        row = ([condition], onsets, durations)\n",
      "        bspm_inputs.append(row)\n",
      "    bspm_inputs = bspm_inputs\n",
      "    b = {'ips': bips, 'spm_inputs': bspm_inputs, 'RT': brt, 'item_orders': bitem_orders, 'run': brun, 'key': bkey}\n",
      "    return b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subjects, items, intensities=[],[],[]\n",
      "for bf in behavioralfiles:\n",
      "    b = extractbehave(bf)\n",
      "    subjid=bf[len(behavedir)+1:len(behavedir)+11]\n",
      "    subjects.extend([subjid for i in b['item_orders']])\n",
      "    if type(b['item_orders'][0])!=list:\n",
      "        itemlist=[el for el in b['item_orders']]\n",
      "    else:\n",
      "        itemlist=[el[0] for el in b['item_orders']]\n",
      "    items.extend(itemlist)\n",
      "    intensities.extend(b['key'])\n",
      "intensitydf=pd.DataFrame(data={'subjid':subjects, 'items':items, 'intensities':intensities})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fillqnum(qnum):\n",
      "    if qnum<10:\n",
      "        nqnum='q00%.0f' %qnum\n",
      "    elif qnum<100:\n",
      "        nqnum='q0%.0f' %qnum\n",
      "    else:\n",
      "        nqnum='q%.0f' %qnum\n",
      "    return nqnum\n",
      "mapping=pd.read_csv(stimfile)[['stimname', 'qnum']]\n",
      "mapping['qnum']=mapping['qnum'].apply(fillqnum)\n",
      "mappingdict={row.stimname:row.qnum for index,row in mapping.iterrows()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def addqnum(itemname, mappingdict=None):\n",
      "    qnum=mappingdict[itemname]\n",
      "    return 'q%.0f' % int(qnum[1:])\n",
      "def checkpain(item):\n",
      "    return not 'PAI' in item\n",
      "intensitydf=intensitydf[intensitydf['items'].apply(checkpain)]\n",
      "intensitydf['qnum']=intensitydf['items'].apply(addqnum, mappingdict=mappingdict)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intensitydf.to_csv(savefile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "intensitydf.qnum.unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "array(['q113', 'q139', 'q163', 'q20', 'q193', 'q109', 'q35', 'q175', 'q26',\n",
        "       'q89', 'q51', 'q92', 'q130', 'q80', 'q7', 'q69', 'q46', 'q160',\n",
        "       'q186', 'q148', 'q132', 'q143', 'q47', 'q200', 'q72', 'q170',\n",
        "       'q105', 'q65', 'q23', 'q171', 'q83', 'q115', 'q190', 'q128', 'q94',\n",
        "       'q158', 'q17', 'q4', 'q38', 'q52', 'q45', 'q185', 'q78', 'q66',\n",
        "       'q2', 'q11', 'q103', 'q96', 'q82', 'q141', 'q168', 'q178', 'q134',\n",
        "       'q195', 'q111', 'q124', 'q36', 'q155', 'q55', 'q28', 'q135', 'q84',\n",
        "       'q49', 'q68', 'q181', 'q164', 'q37', 'q15', 'q99', 'q116', 'q57',\n",
        "       'q129', 'q151', 'q79', 'q102', 'q180', 'q150', 'q3', 'q196', 'q30',\n",
        "       'q10', 'q71', 'q118', 'q159', 'q86', 'q179', 'q189', 'q21', 'q98',\n",
        "       'q101', 'q19', 'q123', 'q56', 'q31', 'q145', 'q197', 'q64', 'q161',\n",
        "       'q50', 'q140', 'q104', 'q119', 'q91', 'q137', 'q54', 'q63', 'q166',\n",
        "       'q153', 'q149', 'q40', 'q25', 'q194', 'q44', 'q75', 'q176', 'q125',\n",
        "       'q5', 'q183', 'q81', 'q12', 'q77', 'q184', 'q120', 'q32', 'q85',\n",
        "       'q67', 'q100', 'q173', 'q154', 'q121', 'q13', 'q165', 'q192',\n",
        "       'q138', 'q106', 'q146', 'q59', 'q9', 'q43', 'q24', 'q199', 'q58',\n",
        "       'q144', 'q87', 'q136', 'q41', 'q6', 'q167', 'q22', 'q110', 'q34',\n",
        "       'q73', 'q152', 'q95', 'q127', 'q187', 'q18', 'q174', 'q112', 'q62',\n",
        "       'q147', 'q117', 'q172', 'q74', 'q39', 'q198', 'q188', 'q107', 'q29',\n",
        "       'q16', 'q90', 'q8', 'q157', 'q169', 'q61', 'q122', 'q42', 'q93',\n",
        "       'q60', 'q131', 'q97', 'q162', 'q114', 'q48', 'q53', 'q76', 'q27',\n",
        "       'q126', 'q70', 'q142', 'q14', 'q156', 'q1', 'q88', 'q191', 'q177',\n",
        "       'q108', 'q133', 'q33', 'q182'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}